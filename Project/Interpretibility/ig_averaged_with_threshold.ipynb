{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da47985",
   "metadata": {
    "papermill": {
     "duration": 0.003648,
     "end_time": "2025-11-23T20:20:24.673316",
     "exception": false,
     "start_time": "2025-11-23T20:20:24.669668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a07f87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:20:24.680239Z",
     "iopub.status.busy": "2025-11-23T20:20:24.679974Z",
     "iopub.status.idle": "2025-11-23T20:21:43.438430Z",
     "shell.execute_reply": "2025-11-23T20:21:43.437373Z"
    },
    "papermill": {
     "duration": 78.763882,
     "end_time": "2025-11-23T20:21:43.440109",
     "exception": false,
     "start_time": "2025-11-23T20:20:24.676227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.3\r\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\r\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 6.33.0\r\n",
      "    Uninstalling protobuf-6.33.0:\r\n",
      "      Successfully uninstalled protobuf-6.33.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\r\n",
      "Collecting transformers-interpret\r\n",
      "  Downloading transformers_interpret-0.10.0-py3-none-any.whl.metadata (45 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting captum>=0.3.1 (from transformers-interpret)\r\n",
      "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\r\n",
      "Requirement already satisfied: ipython<8.0.0,>=7.31.1 in /usr/local/lib/python3.11/dist-packages (from transformers-interpret) (7.34.0)\r\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from transformers-interpret) (4.53.3)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from captum>=0.3.1->transformers-interpret) (3.7.2)\r\n",
      "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from captum>=0.3.1->transformers-interpret) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from captum>=0.3.1->transformers-interpret) (25.0)\r\n",
      "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from captum>=0.3.1->transformers-interpret) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from captum>=0.3.1->transformers-interpret) (4.67.1)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (75.2.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.19.2)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (4.4.2)\r\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.7.5)\r\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (5.7.1)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (3.0.51)\r\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (2.19.2)\r\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.2.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.1.7)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (4.9.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->transformers-interpret) (3.20.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.36.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->transformers-interpret) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->transformers-interpret) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->transformers-interpret) (2.32.5)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.21.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.5.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->transformers-interpret) (2025.10.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->transformers-interpret) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->transformers-interpret) (1.2.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<8.0.0,>=7.31.1->transformers-interpret) (0.8.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum>=0.3.1->transformers-interpret) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum>=0.3.1->transformers-interpret) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum>=0.3.1->transformers-interpret) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum>=0.3.1->transformers-interpret) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum>=0.3.1->transformers-interpret) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum>=0.3.1->transformers-interpret) (2.4.1)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<8.0.0,>=7.31.1->transformers-interpret) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.31.1->transformers-interpret) (0.2.13)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum>=0.3.1->transformers-interpret) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum>=0.3.1->transformers-interpret) (3.1.6)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10->captum>=0.3.1->transformers-interpret)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10->captum>=0.3.1->transformers-interpret)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10->captum>=0.3.1->transformers-interpret)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10->captum>=0.3.1->transformers-interpret)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10->captum>=0.3.1->transformers-interpret)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10->captum>=0.3.1->transformers-interpret)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10->captum>=0.3.1->transformers-interpret)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10->captum>=0.3.1->transformers-interpret)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10->captum>=0.3.1->transformers-interpret)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum>=0.3.1->transformers-interpret) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum>=0.3.1->transformers-interpret) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum>=0.3.1->transformers-interpret) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10->captum>=0.3.1->transformers-interpret)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum>=0.3.1->transformers-interpret) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum>=0.3.1->transformers-interpret) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->captum>=0.3.1->transformers-interpret) (1.3.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (1.4.8)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (2.9.0.post0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (2025.10.5)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->captum>=0.3.1->transformers-interpret) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->captum>=0.3.1->transformers-interpret) (3.0.3)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->captum>=0.3.1->transformers-interpret) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->captum>=0.3.1->transformers-interpret) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->captum>=0.3.1->transformers-interpret) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0->captum>=0.3.1->transformers-interpret) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0->captum>=0.3.1->transformers-interpret) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0->captum>=0.3.1->transformers-interpret) (2024.2.0)\r\n",
      "Downloading transformers_interpret-0.10.0-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading captum-0.8.0-py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, captum, transformers-interpret\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed captum-0.8.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-interpret-0.10.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.3\n",
    "!pip install transformers-interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9022dbbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:21:43.490595Z",
     "iopub.status.busy": "2025-11-23T20:21:43.490324Z",
     "iopub.status.idle": "2025-11-23T20:22:22.298344Z",
     "shell.execute_reply": "2025-11-23T20:22:22.297700Z"
    },
    "papermill": {
     "duration": 38.834658,
     "end_time": "2025-11-23T20:22:22.299722",
     "exception": false,
     "start_time": "2025-11-23T20:21:43.465064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 20:22:03.523402: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763929323.709233      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763929323.766034      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import shap\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "\n",
    "import transformers\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24cf449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:22.350290Z",
     "iopub.status.busy": "2025-11-23T20:22:22.349344Z",
     "iopub.status.idle": "2025-11-23T20:22:22.356637Z",
     "shell.execute_reply": "2025-11-23T20:22:22.356128Z"
    },
    "papermill": {
     "duration": 0.03329,
     "end_time": "2025-11-23T20:22:22.357773",
     "exception": false,
     "start_time": "2025-11-23T20:22:22.324483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c5ad679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:22.407858Z",
     "iopub.status.busy": "2025-11-23T20:22:22.407298Z",
     "iopub.status.idle": "2025-11-23T20:22:22.411724Z",
     "shell.execute_reply": "2025-11-23T20:22:22.410975Z"
    },
    "papermill": {
     "duration": 0.030378,
     "end_time": "2025-11-23T20:22:22.412978",
     "exception": false,
     "start_time": "2025-11-23T20:22:22.382600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba2aeb6",
   "metadata": {
    "papermill": {
     "duration": 0.02425,
     "end_time": "2025-11-23T20:22:22.462069",
     "exception": false,
     "start_time": "2025-11-23T20:22:22.437819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4831658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:22.512483Z",
     "iopub.status.busy": "2025-11-23T20:22:22.511788Z",
     "iopub.status.idle": "2025-11-23T20:22:22.828401Z",
     "shell.execute_reply": "2025-11-23T20:22:22.827699Z"
    },
    "papermill": {
     "duration": 0.342919,
     "end_time": "2025-11-23T20:22:22.829517",
     "exception": false,
     "start_time": "2025-11-23T20:22:22.486598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'user'],\n",
       "        num_rows: 25263\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'label', 'user'],\n",
       "        num_rows: 2807\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'user'],\n",
       "        num_rows: 3115\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_from_disk(\"/kaggle/input/erisk25/erisk_processed/erisk_processed\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac3d31",
   "metadata": {
    "papermill": {
     "duration": 0.02621,
     "end_time": "2025-11-23T20:22:22.881332",
     "exception": false,
     "start_time": "2025-11-23T20:22:22.855122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d27a980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:22.932235Z",
     "iopub.status.busy": "2025-11-23T20:22:22.931658Z",
     "iopub.status.idle": "2025-11-23T20:22:28.149258Z",
     "shell.execute_reply": "2025-11-23T20:22:28.148633Z"
    },
    "papermill": {
     "duration": 5.244402,
     "end_time": "2025-11-23T20:22:28.150664",
     "exception": false,
     "start_time": "2025-11-23T20:22:22.906262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = '/kaggle/input/disorbert-finetuned-models/pytorch/default/1/finetuned-models/bert-base-cased-finetuned/checkpoint-5530'\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path, truncation=True, max_length=512)\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_path, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ebe4487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:28.201596Z",
     "iopub.status.busy": "2025-11-23T20:22:28.201373Z",
     "iopub.status.idle": "2025-11-23T20:22:28.206176Z",
     "shell.execute_reply": "2025-11-23T20:22:28.205629Z"
    },
    "papermill": {
     "duration": 0.031485,
     "end_time": "2025-11-23T20:22:28.207196",
     "exception": false,
     "start_time": "2025-11-23T20:22:28.175711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='/kaggle/input/disorbert-finetuned-models/pytorch/default/1/finetuned-models/bert-base-cased-finetuned/checkpoint-5530', vocab_size=28996, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673de345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:28.257180Z",
     "iopub.status.busy": "2025-11-23T20:22:28.256945Z",
     "iopub.status.idle": "2025-11-23T20:22:28.262316Z",
     "shell.execute_reply": "2025-11-23T20:22:28.261770Z"
    },
    "papermill": {
     "duration": 0.031867,
     "end_time": "2025-11-23T20:22:28.263367",
     "exception": false,
     "start_time": "2025-11-23T20:22:28.231500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "941ae53e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:28.313621Z",
     "iopub.status.busy": "2025-11-23T20:22:28.313423Z",
     "iopub.status.idle": "2025-11-23T20:22:28.318226Z",
     "shell.execute_reply": "2025-11-23T20:22:28.317695Z"
    },
    "papermill": {
     "duration": 0.031219,
     "end_time": "2025-11-23T20:22:28.319328",
     "exception": false,
     "start_time": "2025-11-23T20:22:28.288109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers_interpret.explainers.text.sequence_classification.SequenceClassificationExplainer at 0x79b29c3cdb10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer = SequenceClassificationExplainer(model, tokenizer)\n",
    "explainer.n_steps = 8\n",
    "explainer.internal_batch_size = 1\n",
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f9a37b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:28.369157Z",
     "iopub.status.busy": "2025-11-23T20:22:28.368893Z",
     "iopub.status.idle": "2025-11-23T20:22:28.510400Z",
     "shell.execute_reply": "2025-11-23T20:22:28.509554Z"
    },
    "papermill": {
     "duration": 0.167635,
     "end_time": "2025-11-23T20:22:28.511563",
     "exception": false,
     "start_time": "2025-11-23T20:22:28.343928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3115,\n",
       " \"Itachi uchiha not that I am a huge fan but man his story hits hard 1. Naruto Shipudden / OG Naruto 2. Attack on Titan 3. Saiki 4. Berserk (manga) 5.Demon Slayer / jujutsu kaisen Hashirama hit pics I have watches 6 of them including Naruto both parts but I am in cbse Dead space 2 when I was a kid Very bad tier Come on guys you all know it's Itachi uchiha One piece and Naruto fans be hating you Real life oututsuki Go to a country where dental care is cheap like India and get your teeth fixed it will cost you less than usual high prices I can fix my teeth under 400 dollors Bro they all contain same amount of DNA so even any one of them have been fused you will be still you but XX or XY sperm have been fused you would have a different gender Naruto-kun Well guys we don't lose wars like america Mob psycho 100 is shit and boring Bro told the truth and don't lie we all know that ep 1071 was at peak hype and the hype died at 1072 ep WOW loyal fans Your Twitter was attacked by T-ELON missile and only X was recovered from the debris Didn't saw it comming Then use jiraya for pen stand It already exists hentai There is a junji ito manga named Billy and whenever I see this I recall the manga Wowwwwwwwww. Soooo good I got creeped out rather than horny Junji ito is my favorate manga writer Watch Charlotte, rascal does not dream of bunny girl sempai , junji ito collection (18+) , black clover , fullmetal alchemist brotherhood My writing was \")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts = list(dataset['test']['text'])\n",
    "len(test_texts), test_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b59b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:28.562375Z",
     "iopub.status.busy": "2025-11-23T20:22:28.562118Z",
     "iopub.status.idle": "2025-11-23T20:22:29.429122Z",
     "shell.execute_reply": "2025-11-23T20:22:29.428428Z"
    },
    "papermill": {
     "duration": 0.893734,
     "end_time": "2025-11-23T20:22:29.430547",
     "exception": false,
     "start_time": "2025-11-23T20:22:28.536813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"I have been staying in bed all day and feel empty.\"\n",
    "word_attributions = explainer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bc6a22a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:29.481850Z",
     "iopub.status.busy": "2025-11-23T20:22:29.481594Z",
     "iopub.status.idle": "2025-11-23T20:22:29.520292Z",
     "shell.execute_reply": "2025-11-23T20:22:29.519696Z"
    },
    "papermill": {
     "duration": 0.065467,
     "end_time": "2025-11-23T20:22:29.521343",
     "exception": false,
     "start_time": "2025-11-23T20:22:29.455876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>2.15</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> staying                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bed                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> all                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> day                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> feel                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> empty                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>2.15</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> been                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> staying                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bed                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> all                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> day                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> feel                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> empty                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b4b55d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:29.573096Z",
     "iopub.status.busy": "2025-11-23T20:22:29.572801Z",
     "iopub.status.idle": "2025-11-23T20:22:29.576792Z",
     "shell.execute_reply": "2025-11-23T20:22:29.576114Z"
    },
    "papermill": {
     "duration": 0.030636,
     "end_time": "2025-11-23T20:22:29.577854",
     "exception": false,
     "start_time": "2025-11-23T20:22:29.547218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 510\n",
    "\n",
    "def truncate_text(text, max_tokens=MAX_LEN):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if len(tokens) > max_tokens:\n",
    "        tokens = tokens[:max_tokens]\n",
    "    return tokenizer.convert_tokens_to_string(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f586c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:29.629506Z",
     "iopub.status.busy": "2025-11-23T20:22:29.628852Z",
     "iopub.status.idle": "2025-11-23T20:22:29.632383Z",
     "shell.execute_reply": "2025-11-23T20:22:29.631801Z"
    },
    "papermill": {
     "duration": 0.030848,
     "end_time": "2025-11-23T20:22:29.633441",
     "exception": false,
     "start_time": "2025-11-23T20:22:29.602593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4724ce79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:29.684903Z",
     "iopub.status.busy": "2025-11-23T20:22:29.684630Z",
     "iopub.status.idle": "2025-11-23T20:22:29.690017Z",
     "shell.execute_reply": "2025-11-23T20:22:29.689392Z"
    },
    "papermill": {
     "duration": 0.032508,
     "end_time": "2025-11-23T20:22:29.691083",
     "exception": false,
     "start_time": "2025-11-23T20:22:29.658575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_global_impact_ig(explainer, text_list):\n",
    "    global_word_scores = {}\n",
    "\n",
    "    for text in tqdm(test_texts):\n",
    "        text = truncate_text(text)\n",
    "        result = explainer(text)\n",
    "        cleanup() \n",
    "\n",
    "        for word, score in result:\n",
    "            word = word.replace(\"##\", \"\")\n",
    "\n",
    "            if word in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
    "                continue\n",
    "\n",
    "            if word not in global_word_scores:\n",
    "                global_word_scores[word] = {\"total_score\": 0.0, \"frequency\": 0}\n",
    "\n",
    "            global_word_scores[word][\"total_score\"] += score\n",
    "            global_word_scores[word][\"frequency\"] += 1\n",
    "\n",
    "    for key, value in global_word_scores.items():\n",
    "        global_word_scores[key]['avg_score'] = value['total_score'] / value['frequency'] if value['frequency'] > 8 else 0\n",
    "\n",
    "    return global_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd41c2cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:22:29.742571Z",
     "iopub.status.busy": "2025-11-23T20:22:29.742281Z",
     "iopub.status.idle": "2025-11-23T20:44:13.642088Z",
     "shell.execute_reply": "2025-11-23T20:44:13.640974Z"
    },
    "papermill": {
     "duration": 1303.927299,
     "end_time": "2025-11-23T20:44:13.643419",
     "exception": false,
     "start_time": "2025-11-23T20:22:29.716120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3115/3115 [21:43<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Word  Total_Attribution  Frequency  Average_Attribution\n",
      "2416        icidal           4.469277         17             0.262899\n",
      "5428          lone           3.772235         20             0.188612\n",
      "3046      pressive           1.561531         11             0.141957\n",
      "2372     substance           2.208905         16             0.138057\n",
      "3389           xin           1.459004         11             0.132637\n",
      "2553     treatment           6.070323         46             0.131964\n",
      "3039          mani           1.709778         13             0.131521\n",
      "4772       confess           1.339847         11             0.121804\n",
      "2296    prescribed           2.187816         19             0.115148\n",
      "151            mob           1.136275         10             0.113628\n",
      "1732       teenage           1.442037         13             0.110926\n",
      "9959     intensity           1.300465         12             0.108372\n",
      "1673          tomb           0.974791          9             0.108310\n",
      "7135          lica           1.173657         11             0.106696\n",
      "5244        houses           1.594934         15             0.106329\n",
      "2767  psychiatrist           2.651941         25             0.106078\n",
      "2689    disability           1.587522         15             0.105835\n",
      "5330      football           3.913308         37             0.105765\n",
      "1779            gy          14.523393        140             0.103739\n",
      "2511   medications           3.704560         36             0.102904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_stats = get_global_impact_ig(explainer, test_texts)\n",
    "\n",
    "df_ig = pd.DataFrame.from_dict(word_stats, orient=\"index\").reset_index()\n",
    "df_ig.columns = [\"Word\", \"Total_Attribution\", \"Frequency\", \"Average_Attribution\"]\n",
    "\n",
    "# Sort and print top depression indicators\n",
    "top_depression_words = df_ig.sort_values(by=\"Average_Attribution\", ascending=False).head(20)\n",
    "print(top_depression_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f07d0e",
   "metadata": {
    "papermill": {
     "duration": 0.144401,
     "end_time": "2025-11-23T20:44:13.936708",
     "exception": false,
     "start_time": "2025-11-23T20:44:13.792307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8657032,
     "sourceId": 13839231,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 500166,
     "modelInstanceId": 484690,
     "sourceId": 642787,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1436.679584,
   "end_time": "2025-11-23T20:44:17.316996",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-23T20:20:20.637412",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
